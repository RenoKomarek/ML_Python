{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f063bc89",
   "metadata": {},
   "source": [
    "# Self-composed ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09fb61",
   "metadata": {},
   "source": [
    "An ensemble combines the outcomes of two or more machine learning models. Thereby you can achieve better results, but you will have a longer training time. There are two possible ways to classify:\n",
    "- **Hard Voting:** The label that is predicted by the majority of the models is chosen.\n",
    "- **Soft Voting:** Every model returns probabilities for each label. Then these values are used to calculate the mean or median probability to predict the label (Simic, 2024).\n",
    "\n",
    "Because we are looking for the best possible F1-Score, Grid-Search chooses Soft-Voting, as this approach considers the probability, which results in a better performance. \n",
    "\n",
    "For each model we use the hyperparamters chosen by their individual Grid-Search. Moreover, we use all seven models, because they add diversity and have different strengths. This also minimizes the risk of a false prediction, because one single model with a weakness is not deciding on its own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cee05e",
   "metadata": {},
   "source": [
    "Simic, M. (2024, March 18). Hard vs. Soft Voting Classifiers. Baeldung. https://www.baeldung.com/cs/hard-vs-soft-voting-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbfaa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold, GridSearchCV\n\u001b[0;32m      8\u001b[0m estimator \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m----> 9\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mbest_model_knn\u001b[49m),\n\u001b[0;32m     10\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogisticRegression\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_lg),\n\u001b[0;32m     11\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_svc),\n\u001b[0;32m     12\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_dt),\n\u001b[0;32m     13\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_rf),\n\u001b[0;32m     14\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradientBoostingClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_gbc),\n\u001b[0;32m     15\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m'\u001b[39m, best_model_xgb)\n\u001b[0;32m     16\u001b[0m ]\n\u001b[0;32m     18\u001b[0m ce \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators \u001b[38;5;241m=\u001b[39m estimator)\n\u001b[0;32m     20\u001b[0m param_grid_ce \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoting\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     ]\n\u001b[0;32m     32\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model_knn' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "estimator = [\n",
    "('KNN', best_model_knn),\n",
    "('LogisticRegression', best_model_lg),\n",
    "('SVC', best_model_svc),\n",
    "('DT', best_model_dt),\n",
    "('RandomForest', best_model_rf),\n",
    "('GradientBoostingClassifier', best_model_gbc),\n",
    "('XGB', best_model_xgb)\n",
    "]\n",
    "\n",
    "ce = VotingClassifier(estimators = estimator)\n",
    "\n",
    "param_grid_ce = {\n",
    "    'voting': ['soft', 'hard'],\n",
    "    'weights': [\n",
    "        None,\n",
    "        [2, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 2, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 2, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 2, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 2, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 2, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 2],\n",
    "    ]\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=ce, param_grid=param_grid_ce, cv=kfold , scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_ce = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\\n\", best_params)\n",
    "\n",
    "y_pred = best_model_ce.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"\\nF1 Score:\\n\", f1)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126207b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "estimator = [\n",
    "('KNN', best_model_knn),\n",
    "('LogisticRegression', best_model_lg),\n",
    "('SVC', best_model_svc),\n",
    "('DT', best_model_dt),\n",
    "('RandomForest', best_model_rf),\n",
    "('GradientBoostingClassifier', best_model_gbc),\n",
    "('XGB', best_model_xgb)\n",
    "]\n",
    "\n",
    "ce = VotingClassifier(estimators = estimator)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "weights = [ # List of random weights for models\n",
    "    None,\n",
    "    [np.random.uniform(0.5, 2) for _ in range(7)] for _ in range(200)\n",
    "]\n",
    "\n",
    "param_grid_ce = {\n",
    "    'voting': ['soft', 'hard'],\n",
    "    'weights': weights\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=ce, param_grid=param_grid_ce, cv=kfold , scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_ce = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\\n\", best_params)\n",
    "\n",
    "y_pred = best_model_ce.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"\\nF1 Score:\\n\", f1)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
